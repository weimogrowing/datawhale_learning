# 语言模型的监督式微调（SFT）

- 基础模型通常基于token回答，对用户不够友好
- SFT训练通过交叉熵损失训练模型，鼓励模型最大化每个prompt下生成目标回应的概率
- 微调后的模型可以针对prompt给出对用户友好的回答

# SFT使用场景

- 激发新的模型能力

  - 预训练模型->基于对话的模型
  - 让模型学会推理
  - 让模型有使用工具的能力
- 提升模型能力

  - 通过大模型生成高质量数据，再蒸馏到小模型

# SFT 数据策划原则

- 蒸馏
- top-k
- 过滤

核心原则是质量>数量

# 全参数微调 vs 参数高效微调

- 全参数微调

  - 提升模型能力，但是计算资源花费多
- 参数高效微调

  - 速度快但是效果有限
